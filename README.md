# 微信智能回复助手

基于本地 AI 大模型（Qwen2.5）的微信自动回复 Android 应用。

**一个 App 搞定一切。AI 内嵌在 App 中，完全离线运行，无需安装 Termux，无需联网。**

---

## 功能特性

- **一键使用**：App 内直接下载模型，无需任何其他工具
- **智能回复**：本地 AI 模型生成自然的聊天回复
- **联系人白名单**：只回复指定的联系人（支持 20+ 人）
- **个性化风格**：每个联系人可以设置不同的回复风格
- **对话记忆**：记住每个联系人的聊天上下文（最近 20 条）
- **完全离线**：AI 引擎内嵌在 App 中，无需网络
- **隐私保护**：不上传任何数据到云端
- **安全防护**：
  - 随机回复延迟（模拟真人打字）
  - 频率限制（每人每分钟上限）
  - 每日回复总量限制
  - 工作时间段设置
  - 敏感词过滤（转账、密码等自动跳过）

---

## 使用流程

```
安装 App → 下载模型（约 1GB，WiFi 下几分钟）→ 添加联系人 → 开始使用
```

### 第一步：编译安装

1. 克隆项目：
   ```bash
   git clone <本项目地址>
   cd WeChatAutoReply
   ```

2. 克隆 llama.cpp 源码（编译需要）：
   ```bash
   git clone https://github.com/ggerganov/llama.cpp
   ```

3. 用 Android Studio 打开项目，编译安装到手机

### 第二步：下载 AI 模型

1. 打开 App
2. 进入「设置」
3. 选择一个模型，点击「下载」
4. 等待下载完成（需要 WiFi，仅此一次）

**推荐选择：**

| 模型 | 大小 | 适合 |
|------|------|------|
| **Qwen2.5 1.5B（推荐）** | ~1GB | 大多数手机 |
| Qwen2.5 0.5B（轻量） | ~400MB | 内存较小的手机 |
| Qwen2.5 3B（高质量） | ~2GB | 旗舰手机，效果最好 |

### 第三步：授权通知权限

1. 在主页点击「通知访问权限」
2. 在系统设置中找到「微信智能回复」
3. 开启权限

### 第四步：添加联系人

1. 进入「联系人管理」
2. 点击 + 按钮
3. 输入联系人微信名称（必须和微信通知显示的名称一致）
4. 设置回复风格（可选）

### 第五步：开启！

打开主页的总开关，搞定！

---

## 回复风格示例

| 联系人 | 风格设置 | 效果 |
|--------|---------|------|
| cc | 朋友之间随意聊天，回复简短自然 | "在呢，咋啦？" |
| 老妈 | 温和耐心地回复妈妈，多关心她 | "在的妈，怎么了？" |
| 老板 | 正式礼貌的工作沟通风格 | "在的，请问有什么事吗？" |

---

## 工作原理

```
微信消息 → 系统通知 → App 监听通知 → 匹配白名单
                                        ↓
                        本地 Qwen2.5 生成回复（内嵌引擎）
                                        ↓
                        随机延迟 → 通过通知快捷回复发送
```

**技术方案**：
- 使用 Android `NotificationListenerService` 监听微信通知
- 通过 JNI 调用内嵌的 llama.cpp 引擎进行本地推理
- 通过通知的 `RemoteInput` 快捷回复功能发送消息
- **全程不打开微信 App，不使用无障碍服务，不截图，不联网**

---

## 项目结构

```
WeChatAutoReply/
├── llama.cpp/                          # llama.cpp 源码（需手动克隆）
├── app/src/main/
│   ├── cpp/
│   │   ├── CMakeLists.txt              # 本地库编译配置
│   │   └── llama-jni.cpp              # C++ JNI 桥接层
│   ├── java/com/example/wechatautoreply/
│   │   ├── App.kt                      # Application 初始化
│   │   ├── ai/
│   │   │   ├── LlamaEngine.kt         # 本地推理引擎（JNI 封装）
│   │   │   ├── LlamaClient.kt         # AI 客户端统一接口
│   │   │   └── ModelManager.kt        # 模型下载管理
│   │   ├── data/
│   │   │   ├── ContactManager.kt      # 联系人管理
│   │   │   ├── ReplyLogManager.kt     # 回复日志管理
│   │   │   └── SettingsManager.kt     # 设置管理
│   │   ├── model/                      # 数据模型
│   │   ├── service/
│   │   │   ├── WeChatNotificationService.kt  # 核心：通知监听服务
│   │   │   └── LlamaService.kt        # 前台保活服务
│   │   └── ui/                         # 界面
│   └── res/                            # 资源文件
└── README.md
```

---

## 安全设置建议

| 设置项 | 建议值 | 说明 |
|--------|--------|------|
| 回复延迟 | 2-6 秒 | 模拟真人打字速度 |
| 每人每分钟上限 | 3 条 | 避免频率过高 |
| 每日回复上限 | 100 条 | 控制总量 |
| 工作时间 | 8:00-23:00 | 凌晨不回复 |
| 敏感词 | 转账,密码,红包,验证码 | 涉及金钱安全的不回复 |

---

## 手机要求

| 配置 | 最低要求 | 推荐 |
|------|---------|------|
| 系统 | Android 8.0+ | Android 10+ |
| 内存 | 4GB | 6GB+ |
| 存储 | 2GB 可用 | 4GB+ |
| CPU | 骁龙 660+ | 骁龙 8 系 |

---

## 免责声明

⚠️ **本项目仅供学习和研究使用。**

- 使用自动化工具可能违反微信使用条款
- 使用不当可能导致微信账号被限制或封禁
- 请勿用于骚扰、诈骗等违法用途
- 作者不对使用本软件造成的任何后果负责
- 建议先用小号测试，确认稳定后再谨慎使用

---

## 许可证

MIT License
